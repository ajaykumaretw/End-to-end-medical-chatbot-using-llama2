{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import uuid\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV='gcp-starter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from PDF file\n",
    "def load_pdf(data):\n",
    " loader=DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    " documents=loader.load()\n",
    " return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheGALE\\nENCYCLOPEDIA\\nofMEDICINE\\nSECOND EDITION'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\End-to-end-medical-chatbot-using-llama2\\mchatbot\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embedding_model.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index name\n",
    "index_name = \"medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates an index using the API key stored in the client 'pc'.\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws', \n",
    "        region='us-east-1'\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'text_chunks' is a list of objects where each object has a 'page_content' attribute\n",
    "#Example: text_chunks = [TextChunk(page_content=\"Text 1\"), TextChunk(page_content=\"Text 2\")]\n",
    "# Generate embeddings for each text chunk\n",
    "embeddings = [embedding_model.embed_query(t.page_content) for t in text_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7020"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0017460824456065893,\n",
       " -0.03350288048386574,\n",
       " -0.03290391340851784,\n",
       " 0.007168074604123831,\n",
       " -0.01460330095142126,\n",
       " 0.010261906310915947,\n",
       " -0.011515316553413868,\n",
       " 0.22930210828781128,\n",
       " -0.023232368752360344,\n",
       " 0.004120390862226486,\n",
       " -0.036560822278261185,\n",
       " 0.08592111617326736,\n",
       " 0.012972141616046429,\n",
       " 0.05221789330244064,\n",
       " -0.10232619196176529,\n",
       " -0.0031390218064188957,\n",
       " -0.012686936184763908,\n",
       " 0.00047184049617499113,\n",
       " -0.028485851362347603,\n",
       " -0.05025918409228325,\n",
       " 0.01155098993331194,\n",
       " 0.0778065174818039,\n",
       " 0.09282821416854858,\n",
       " -0.013797298073768616,\n",
       " -0.016935091465711594,\n",
       " -0.02595585398375988,\n",
       " -0.04956509545445442,\n",
       " -0.046131327748298645,\n",
       " 0.007290528621524572,\n",
       " -0.013553302735090256,\n",
       " 0.03843941166996956,\n",
       " 0.06280472129583359,\n",
       " 0.01835383102297783,\n",
       " 0.008242791518568993,\n",
       " 0.0017155827954411507,\n",
       " -0.03986185044050217,\n",
       " -0.01163862831890583,\n",
       " 0.016446184366941452,\n",
       " 0.025595610961318016,\n",
       " 0.09104608744382858,\n",
       " 0.02967270091176033,\n",
       " -0.054160282015800476,\n",
       " -0.04576560854911804,\n",
       " -0.01385387685149908,\n",
       " 0.02577359601855278,\n",
       " 0.010323120281100273,\n",
       " -0.053630903363227844,\n",
       " 0.021221568807959557,\n",
       " 0.01702776364982128,\n",
       " 0.11612217873334885,\n",
       " -0.06963174790143967,\n",
       " -0.09572754800319672,\n",
       " -0.03983991965651512,\n",
       " 0.05236925929784775,\n",
       " 0.02526022307574749,\n",
       " -0.03127453476190567,\n",
       " -0.07005155831575394,\n",
       " -0.05956606566905975,\n",
       " -0.09544862806797028,\n",
       " -0.054121218621730804,\n",
       " -0.0002130381326423958,\n",
       " 0.0002552080841269344,\n",
       " 0.012184829451143742,\n",
       " 0.03684717044234276,\n",
       " -0.09168802946805954,\n",
       " -0.016031526029109955,\n",
       " 0.056772489100694656,\n",
       " -0.061103105545043945,\n",
       " 0.05796806141734123,\n",
       " -0.03652450069785118,\n",
       " -0.021421397104859352,\n",
       " -0.047219835221767426,\n",
       " 0.03454085439443588,\n",
       " 0.12064337730407715,\n",
       " -0.013788599520921707,\n",
       " -0.06848540157079697,\n",
       " 0.012004943564534187,\n",
       " -0.0597289614379406,\n",
       " -0.05643807351589203,\n",
       " -0.10106107592582703,\n",
       " 0.05889028310775757,\n",
       " -0.02077680081129074,\n",
       " 0.09746566414833069,\n",
       " 0.07813999056816101,\n",
       " -0.03523318096995354,\n",
       " -0.014866258949041367,\n",
       " 0.04035712778568268,\n",
       " 0.07460876554250717,\n",
       " -0.013026436790823936,\n",
       " -0.02844158187508583,\n",
       " 0.10370919853448868,\n",
       " 0.01950635015964508,\n",
       " 0.029694203287363052,\n",
       " 0.007636248134076595,\n",
       " 0.005692522507160902,\n",
       " -0.0007858291501179338,\n",
       " -0.043153293430805206,\n",
       " 0.007750410586595535,\n",
       " -0.017907092347741127,\n",
       " 0.061117928475141525,\n",
       " -0.025316860526800156,\n",
       " -0.10494083166122437,\n",
       " -0.053424883633852005,\n",
       " 0.009893701411783695,\n",
       " 0.014465517364442348,\n",
       " -0.06589170545339584,\n",
       " 0.009222929365932941,\n",
       " -0.13625681400299072,\n",
       " 0.021162530407309532,\n",
       " -0.011618860997259617,\n",
       " 0.034509267657995224,\n",
       " 0.06049511581659317,\n",
       " 0.015652956441044807,\n",
       " -0.012806665152311325,\n",
       " -0.007194939535111189,\n",
       " 0.055682480335235596,\n",
       " 0.07992611080408096,\n",
       " 0.05983532965183258,\n",
       " 0.09587427228689194,\n",
       " 0.018204256892204285,\n",
       " 0.023596465587615967,\n",
       " -0.08910961449146271,\n",
       " -0.007128849159926176,\n",
       " -0.09076817333698273,\n",
       " 0.047233134508132935,\n",
       " 0.004134095273911953,\n",
       " 0.0033979068975895643,\n",
       " -2.0226571500835786e-33,\n",
       " 0.015145675279200077,\n",
       " -0.004016528371721506,\n",
       " 0.046035632491111755,\n",
       " 0.06628157943487167,\n",
       " 0.08750344067811966,\n",
       " 0.03237525746226311,\n",
       " -0.013098536990582943,\n",
       " -0.0653020516037941,\n",
       " 0.0794229581952095,\n",
       " -0.1063862293958664,\n",
       " -0.07034207135438919,\n",
       " 0.038891538977622986,\n",
       " 0.014388086274266243,\n",
       " 0.05448482558131218,\n",
       " -0.10632544010877609,\n",
       " 0.0015779099194332957,\n",
       " -0.07627757638692856,\n",
       " 0.029417991638183594,\n",
       " -0.020254971459507942,\n",
       " -0.010341223329305649,\n",
       " 0.007716163992881775,\n",
       " 0.015365897677838802,\n",
       " -0.03086637333035469,\n",
       " 0.038066718727350235,\n",
       " -0.08467364311218262,\n",
       " 0.061196524649858475,\n",
       " -0.006315947975963354,\n",
       " 0.021086061373353004,\n",
       " 0.09480434656143188,\n",
       " -0.028975779190659523,\n",
       " -0.02469867467880249,\n",
       " -0.02624204196035862,\n",
       " 0.010229112580418587,\n",
       " -0.04816940426826477,\n",
       " -0.050850752741098404,\n",
       " 0.06431734561920166,\n",
       " -0.06250055134296417,\n",
       " -0.01794431544840336,\n",
       " -0.0032577048987150192,\n",
       " -0.002177964197471738,\n",
       " 0.004051036201417446,\n",
       " 0.05613986402750015,\n",
       " 0.02165950834751129,\n",
       " -0.02845911681652069,\n",
       " 0.06688948720693588,\n",
       " -0.018423588946461678,\n",
       " -0.1386347860097885,\n",
       " -6.530748214572668e-05,\n",
       " 0.09188716858625412,\n",
       " -0.05782889574766159,\n",
       " 0.051801227033138275,\n",
       " -0.033399105072021484,\n",
       " 0.06356911361217499,\n",
       " -0.03353032469749451,\n",
       " 0.003560280427336693,\n",
       " 0.05478644371032715,\n",
       " -0.0592782124876976,\n",
       " 0.02796686626970768,\n",
       " 0.019815023988485336,\n",
       " 0.030648209154605865,\n",
       " 0.09453833103179932,\n",
       " 0.07339680194854736,\n",
       " 0.022082852199673653,\n",
       " -0.03439531847834587,\n",
       " -0.008398779667913914,\n",
       " 0.01607745699584484,\n",
       " -0.10198631882667542,\n",
       " -0.10767034441232681,\n",
       " -0.048454053699970245,\n",
       " -0.046985894441604614,\n",
       " -0.12305164337158203,\n",
       " 0.01794605143368244,\n",
       " 0.02716820314526558,\n",
       " 0.04150307551026344,\n",
       " -0.012137890793383121,\n",
       " 0.01613495871424675,\n",
       " 0.007807406131178141,\n",
       " -0.0306963212788105,\n",
       " -0.03695550560951233,\n",
       " -0.07249006628990173,\n",
       " -0.0659404993057251,\n",
       " -0.05230468884110451,\n",
       " 0.02264486625790596,\n",
       " 0.10688148438930511,\n",
       " -0.034376323223114014,\n",
       " -0.007189983502030373,\n",
       " 0.004040635656565428,\n",
       " -0.012765694409608841,\n",
       " -0.0357331745326519,\n",
       " -0.009521350264549255,\n",
       " -0.037608999758958817,\n",
       " 0.025724755600094795,\n",
       " -0.07330161333084106,\n",
       " 0.01839982159435749,\n",
       " -0.01315237581729889,\n",
       " -2.4391511452982312e-33,\n",
       " -0.036498408764600754,\n",
       " -0.0389849953353405,\n",
       " -0.02466081641614437,\n",
       " 0.05277743935585022,\n",
       " 0.05715382844209671,\n",
       " 0.08485236763954163,\n",
       " -0.04777834936976433,\n",
       " 0.04885184392333031,\n",
       " 0.0936603769659996,\n",
       " 0.024455280974507332,\n",
       " 0.10703856498003006,\n",
       " -0.0448780320584774,\n",
       " 0.013439507223665714,\n",
       " 0.010380130261182785,\n",
       " -0.03215838223695755,\n",
       " 0.03756461292505264,\n",
       " -0.024516960605978966,\n",
       " -0.015364293940365314,\n",
       " -0.08388062566518784,\n",
       " 0.07285159081220627,\n",
       " -0.08349566906690598,\n",
       " 0.05313439294695854,\n",
       " -0.0502142570912838,\n",
       " 0.021773861721158028,\n",
       " 0.09023480117321014,\n",
       " 0.014781363308429718,\n",
       " 0.03970919921994209,\n",
       " -0.01778607815504074,\n",
       " -0.018121181055903435,\n",
       " -0.05736511945724487,\n",
       " -0.014359000138938427,\n",
       " -0.01921660825610161,\n",
       " -0.07116210460662842,\n",
       " -0.03887924924492836,\n",
       " -0.06919413059949875,\n",
       " 0.0159933939576149,\n",
       " 0.03935178741812706,\n",
       " -0.06669557839632034,\n",
       " -0.02723979949951172,\n",
       " -0.04119189456105232,\n",
       " 0.0888013020157814,\n",
       " -0.03152485936880112,\n",
       " 0.020989282056689262,\n",
       " 0.0075253150425851345,\n",
       " 0.006864214316010475,\n",
       " -0.0001601586991455406,\n",
       " -0.03395674377679825,\n",
       " -0.019771723076701164,\n",
       " -0.013901462778449059,\n",
       " -0.023474160581827164,\n",
       " 0.05024149641394615,\n",
       " 0.0048158131539821625,\n",
       " 0.003084023017436266,\n",
       " 0.013711323961615562,\n",
       " 0.042688366025686264,\n",
       " -0.01031944528222084,\n",
       " -0.015616321936249733,\n",
       " -0.13140302896499634,\n",
       " 0.039325643330812454,\n",
       " 0.0034622102975845337,\n",
       " 0.0046254112385213375,\n",
       " -0.022172991186380386,\n",
       " -0.07998223602771759,\n",
       " 0.07068222761154175,\n",
       " 0.013251692056655884,\n",
       " 0.013216637074947357,\n",
       " -0.031048664823174477,\n",
       " 0.016299385577440262,\n",
       " 0.07485266774892807,\n",
       " -0.020337803289294243,\n",
       " -0.03757908567786217,\n",
       " 0.002720475196838379,\n",
       " -0.07825033366680145,\n",
       " -0.07273510098457336,\n",
       " -0.0015075484989210963,\n",
       " -0.0015040668658912182,\n",
       " -0.04806787148118019,\n",
       " -0.02269684709608555,\n",
       " 0.0023470765445381403,\n",
       " -0.10254421830177307,\n",
       " -0.010626746341586113,\n",
       " -0.05898867920041084,\n",
       " -0.02825748547911644,\n",
       " 0.018367968499660492,\n",
       " -0.024334082379937172,\n",
       " 0.006143556907773018,\n",
       " 0.058125536888837814,\n",
       " 0.006210036110132933,\n",
       " -0.004125490784645081,\n",
       " 0.004883215297013521,\n",
       " -0.05172747001051903,\n",
       " -0.0026522495318204165,\n",
       " -0.08568166196346283,\n",
       " 0.04144113510847092,\n",
       " -0.007155515253543854,\n",
       " -2.368167884014838e-08,\n",
       " 0.05613086372613907,\n",
       " -0.014770290814340115,\n",
       " -0.0016940382774919271,\n",
       " -0.0011319846380501986,\n",
       " -0.004112938418984413,\n",
       " -0.07847738265991211,\n",
       " -0.032728228718042374,\n",
       " 0.08840587735176086,\n",
       " -0.009142786264419556,\n",
       " 0.08083547651767731,\n",
       " -0.06821238994598389,\n",
       " 0.08852604031562805,\n",
       " 0.018825432285666466,\n",
       " -0.00404413091018796,\n",
       " 0.019472263753414154,\n",
       " 0.05469336733222008,\n",
       " -0.004570754244923592,\n",
       " 0.05013277381658554,\n",
       " -0.020886126905679703,\n",
       " -0.004381011705845594,\n",
       " 0.012420043349266052,\n",
       " -0.04024985432624817,\n",
       " -0.017629491165280342,\n",
       " -0.07264232635498047,\n",
       " 0.027827054262161255,\n",
       " 0.026226604357361794,\n",
       " 0.009220167994499207,\n",
       " 0.02573232725262642,\n",
       " -0.009361235424876213,\n",
       " -0.09865131229162216,\n",
       " -0.03130579739809036,\n",
       " 0.051363471895456314,\n",
       " 0.01132276002317667,\n",
       " -0.0496138297021389,\n",
       " -0.04716366156935692,\n",
       " -0.005473919678479433,\n",
       " 0.06890672445297241,\n",
       " -0.040705177932977676,\n",
       " 0.05423298850655556,\n",
       " -0.019241830334067345,\n",
       " 0.014344971626996994,\n",
       " -0.04443497583270073,\n",
       " -0.025674859061837196,\n",
       " 0.03135461360216141,\n",
       " 0.06115216016769409,\n",
       " -0.02683871239423752,\n",
       " 0.04913514107465744,\n",
       " 0.0564483143389225,\n",
       " 0.027938060462474823,\n",
       " -0.08463849127292633,\n",
       " -0.005661570932716131,\n",
       " 0.007060936652123928,\n",
       " 0.10265117138624191,\n",
       " -0.019236577674746513,\n",
       " -0.08145822584629059,\n",
       " 0.07125058025121689,\n",
       " 0.01803843304514885,\n",
       " -0.017572063952684402,\n",
       " -0.00043015522533096373,\n",
       " -0.10405919700860977,\n",
       " 0.002841504057869315,\n",
       " -0.005556412506848574,\n",
       " 0.10660910606384277,\n",
       " 0.05099726840853691]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medical-chatbot'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x1903a612d90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve index info to get the host\n",
    "index_info = pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deletion_protection': 'disabled',\n",
       " 'dimension': 384,\n",
       " 'host': 'medical-chatbot-omc9wav.svc.aped-4627-b74a.pinecone.io',\n",
       " 'metric': 'cosine',\n",
       " 'name': 'medical-chatbot',\n",
       " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       " 'status': {'ready': True, 'state': 'Ready'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical-chatbot-omc9wav.svc.aped-4627-b74a.pinecone.io\n"
     ]
    }
   ],
   "source": [
    "host=index_info['host']\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_metadata(metadata):\n",
    "    \"\"\"Flatten metadata to simple key-value pairs.\"\"\"\n",
    "    flattened = {}\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, (str, int, float, bool)):\n",
    "            flattened[key] = value\n",
    "        elif isinstance(value, list) and all(isinstance(i, str) for i in value):\n",
    "            flattened[key] = value\n",
    "        else:\n",
    "            # Convert complex structures to JSON strings\n",
    "            flattened[key] = json.dumps(value)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to split vectors into smaller batches\n",
    "def batch_vectors(vectors, batch_size):\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        yield vectors[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 1000 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded 20 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n",
      "Uploaded a total of 7020 vectors to Pinecone index '<pinecone.data.index.Index object at 0x000001903A612D90>'\n"
     ]
    }
   ],
   "source": [
    "# Define batch size (adjust as needed)\n",
    "batch_size = 1000  # Set a batch size that fits within Pinecone's limits\n",
    "\n",
    "# Prepare the batch of vectors to upsert\n",
    "vectors = [(str(uuid.uuid4()), list(embedding), {\n",
    "    \"text\": chunk.page_content,\n",
    "    **flatten_metadata(chunk.metadata),\n",
    "}) for embedding, chunk in zip(embeddings, text_chunks)]\n",
    "namespace=\"ns_medical_chatbot\"\n",
    "# Upsert vectors in batches\n",
    "for batch in batch_vectors(vectors, batch_size):\n",
    "    index.upsert(vectors=batch,namespace=namespace)\n",
    "    print(f\"Uploaded {len(batch)} vectors to Pinecone index '{index}'\")\n",
    "\n",
    "print(f\"Uploaded a total of {len(vectors)} vectors to Pinecone index '{index}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x19039f386d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query_text, top_k=5):\n",
    "     # Generate the embedding for the query text\n",
    "     query_embedding = embedding_model.embed_query(query_text)\n",
    "    # Perform the query using the embedding with keyword arguments\n",
    "     query_result = index.query(\n",
    "     vector=query_embedding,\n",
    "     top_k=top_k,  # number of top results to retrieve\n",
    "     namespace='ns_medical_chatbot',  # specify the namespace\n",
    "     include_metadata=True , # include the actual vector data in the results\n",
    "    )\n",
    "     return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"What are Allergies\"\n",
    "results = query_pinecone(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Matches Found: 5\n",
      "\n",
      "Match Score: 0.68\n",
      "Match Content: GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\n",
      "Allergic rhinitis is commonly triggered by\n",
      "exposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\n",
      "The presence of an allergen causes the\n",
      "body's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\n",
      "IgE molecules attach to mast\n",
      "cells, which contain histamine.HistaminePollen grains\n",
      "Lymphocyte\n",
      "FIRST EXPOSURE\n",
      "Additional Information:\n",
      "  Page: 130.0\n",
      "  Source: data\\Medical_book.pdf\n",
      "Source: data\\Medical_book.pdf\n",
      "Page Number: 130.0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Match Score: 0.68\n",
      "Match Content: allergens are the following:\n",
      "• plant pollens\n",
      "• animal fur and dander\n",
      "• body parts from house mites (microscopic creatures\n",
      "found in all houses)\n",
      "• house dust• mold spores• cigarette smoke• solvents• cleaners\n",
      "Common food allergens include the following:\n",
      "• nuts, especially peanuts, walnuts, and brazil nuts\n",
      "• fish, mollusks, and shellfish• eggs• wheat• milk• food additives and preservatives\n",
      "The following types of drugs commonly cause aller-\n",
      "gic reactions:\n",
      "• penicillin or other antibiotics\n",
      "Additional Information:\n",
      "  Page: 129.0\n",
      "  Source: data\\Medical_book.pdf\n",
      "Source: data\\Medical_book.pdf\n",
      "Page Number: 129.0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Match Score: 0.68\n",
      "Match Content: itchy, scratchy nose, eyes, and throat common in aller-gic rhinitis.\n",
      "The number of possible airborne allergens is enor-\n",
      "Additional Information:\n",
      "  Page: 124.0\n",
      "  Source: data\\Medical_book.pdf\n",
      "Source: data\\Medical_book.pdf\n",
      "Page Number: 124.0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Match Score: 0.68\n",
      "Match Content: KEY TERMS\n",
      "Allergen —A substance that causes an allergy.\n",
      "Anaphylaxis —A sudden, life-threatening allergic\n",
      "reaction.\n",
      "Hallucination —A false or distorted perception of\n",
      "objects, sounds, or events that seems real. Halluci-nations usually result from drugs or mental disor-ders.\n",
      "Histamine —A chemical released from cells in the\n",
      "immune system as part of an allergic reaction.\n",
      "Pregnancy category —A system of classifying\n",
      "Additional Information:\n",
      "  Page: 290.0\n",
      "  Source: data\\Medical_book.pdf\n",
      "Source: data\\Medical_book.pdf\n",
      "Page Number: 290.0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Match Score: 0.67\n",
      "Match Content: treatment is appropriate.\n",
      "Alternative treatment\n",
      "Any alternative treatment for allergies begins with\n",
      "Additional Information:\n",
      "  Page: 134.0\n",
      "  Source: data\\Medical_book.pdf\n",
      "Source: data\\Medical_book.pdf\n",
      "Page Number: 134.0\n",
      "\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of matches found\n",
    "print(f\"Total Matches Found: {len(results['matches'])}\")\n",
    "\n",
    "print(\"\")  # Print a blank line for separation\n",
    "\n",
    "# Iterate over each match in the results\n",
    "for match in results['matches']:\n",
    "    # Display the match score, formatted to two decimal places\n",
    "    print(f\"Match Score: {match['score']:.2f}\")\n",
    "    \n",
    "    # Show the main content of the match\n",
    "    print(f\"Match Content: {match['metadata']['text']}\")\n",
    "    \n",
    "    # Extract and display additional information about the match, excluding the main content\n",
    "    other_metadata = {k: v for k, v in match['metadata'].items() if k != 'text'}\n",
    "    print(\"Additional Information:\")\n",
    "    \n",
    "    # Iterate over additional metadata and display each key-value pair\n",
    "    for key, value in other_metadata.items():\n",
    "        print(f\"  {key.capitalize()}: {value}\")\n",
    "    \n",
    "    # Display the source of the match if available\n",
    "    if 'source' in other_metadata:\n",
    "        print(f\"Source: {other_metadata['source']}\")\n",
    "    else:\n",
    "        print(\"Source: Not provided\")\n",
    "        \n",
    "    # Display the page number of the match if available\n",
    "    if 'page' in other_metadata:\n",
    "        print(f\"Page Number: {other_metadata['page']}\")\n",
    "    else:\n",
    "        print(\"Page Number: Not provided\")\n",
    "        \n",
    "    print()  # Print a blank line for separation\n",
    "    \n",
    "    # Print a line to separate details of different matches\n",
    "    print(\"----------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseRetriever\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List\n",
    "\n",
    "class CustomPineconeRetriever(BaseRetriever):\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        results = query_pinecone(query)\n",
    "        docs = []\n",
    "        for match in results['matches']:\n",
    "            metadata = match['metadata']\n",
    "            text = metadata.pop('text', '')  # Remove 'text' from metadata and use it as the main content\n",
    "            docs.append(Document(page_content=text, metadata=metadata))\n",
    "        return docs\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom retriever\n",
    "custom_retriever = CustomPineconeRetriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\End-to-end-medical-chatbot-using-llama2\\mchatbot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :  S! 2:\n",
      "The informationAllergic re:\n",
      "Hope.\n",
      "There are welcome,thanks, no.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('G:/End-to-end-medical-chatbot-using-llama2/data/Medical_book.pdf')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"G:\\End-to-end-medical-chatbot-using-llama2\\data\\Medical_book.pdf\"\n",
    "Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
